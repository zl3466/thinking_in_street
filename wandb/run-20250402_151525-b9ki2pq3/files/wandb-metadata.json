{
  "os": "Linux-5.14.0-284.86.1.el9_2.x86_64-x86_64-with-glibc2.34",
  "python": "CPython 3.11.11",
  "startedAt": "2025-04-02T19:15:25.702473Z",
  "args": [
    "--output_dir",
    "./log/Qwen2.5-VL-7B-GRPO",
    "--model_name_or_path",
    "Qwen/Qwen2.5-VL-7B-Instruct",
    "--dataset_name",
    "/scratch/zl3466/dataset/NuScenes",
    "--deepspeed",
    "./train/local_scripts/zero3.json",
    "--max_prompt_length",
    "16384",
    "--max_completion_length",
    "768",
    "--per_device_train_batch_size",
    "1",
    "--gradient_accumulation_steps",
    "1",
    "--learning_rate",
    "1e-6",
    "--lr_scheduler_type",
    "cosine",
    "--weight_decay",
    "0.01",
    "--bf16",
    "--logging_steps",
    "1",
    "--gradient_checkpointing",
    "true",
    "--temporal",
    "true",
    "--len_control",
    "true",
    "--attn_implementation",
    "flash_attention_2",
    "--max_pixels",
    "401408",
    "--num_train_epochs",
    "1",
    "--run_name",
    "Video-R1",
    "--save_steps",
    "100",
    "--beta",
    "0.04",
    "--max_grad_norm",
    "5",
    "--save_only_model",
    "false",
    "--num_generations",
    "8"
  ],
  "program": "/scratch/zl3466/github/thinking_in_street/./train/localization/grpo.py",
  "codePath": "train/localization/grpo.py",
  "git": {
    "remote": "https://github.com/zl3466/thinking_in_street.git",
    "commit": "73fdc138435a52beef43d6f582a2bb72023b4b5d"
  },
  "email": "zl3466@nyu.edu",
  "root": "/scratch/zl3466/github/thinking_in_street",
  "host": "gr067.hpc.nyu.edu",
  "executable": "/scratch/zl3466/env/thinking-in-street/bin/python",
  "codePathLocal": "train/localization/grpo.py",
  "cpu_count": 48,
  "cpu_count_logical": 48,
  "gpu": "Quadro RTX 8000",
  "gpu_count": 2,
  "disk": {
    "/": {
      "total": "83845120000",
      "used": "39467995136"
    }
  },
  "memory": {
    "total": "404880871424"
  },
  "cpu": {
    "count": 48,
    "countLogical": 48
  },
  "gpu_nvidia": [
    {
      "name": "Quadro RTX 8000",
      "memoryTotal": "48318382080",
      "cudaCores": 4608,
      "architecture": "Turing"
    },
    {
      "name": "Quadro RTX 8000",
      "memoryTotal": "48318382080",
      "cudaCores": 4608,
      "architecture": "Turing"
    }
  ],
  "slurm": {
    "cluster_name": "greene",
    "conf": "/opt/slurm/etc/slurm.conf",
    "cpu_bind": "quiet,mask_cpu:0x0000FF000000",
    "cpu_bind_list": "0x0000FF000000",
    "cpu_bind_type": "mask_cpu:",
    "cpu_bind_verbose": "quiet",
    "cpus_on_node": "8",
    "cpus_per_task": "8",
    "distribution": "cyclic",
    "gpus_on_node": "2",
    "gtids": "0",
    "job_account": "users",
    "job_cpus_per_node": "8",
    "job_end_time": "1743631332",
    "job_gid": "3507300",
    "job_gpus": "0,1",
    "job_group": "zl3466",
    "job_id": "58968762",
    "job_name": "bash",
    "job_nodelist": "gr067",
    "job_num_nodes": "1",
    "job_partition": "rtx8000,v100,a100_2,a100_1,h100_1,gpu_misc_v100",
    "job_qos": "interact",
    "job_start_time": "1743620532",
    "job_uid": "3507300",
    "job_user": "zl3466",
    "jobid": "58968762",
    "jobtmp": "/state/partition1/job-58968762",
    "launch_node_ipaddr": "10.32.32.5",
    "localid": "0",
    "mem_per_node": "16384",
    "nnodes": "1",
    "nodeid": "0",
    "nodelist": "gr067",
    "nprocs": "1",
    "ntasks": "1",
    "prio_process": "0",
    "procid": "0",
    "pty_port": "55374",
    "pty_win_col": "192",
    "pty_win_row": "20",
    "script_context": "prolog_task",
    "srun_comm_host": "10.32.32.5",
    "srun_comm_port": "55375",
    "step_gpus": "2,3",
    "step_id": "0",
    "step_launcher_port": "55375",
    "step_nodelist": "gr067",
    "step_num_nodes": "1",
    "step_num_tasks": "1",
    "step_tasks_per_node": "1",
    "stepid": "0",
    "submit_dir": "/scratch/zl3466/dataset/NuScenes/train",
    "submit_host": "log-2",
    "task_pid": "1473202",
    "tasks_per_node": "1",
    "tmpdir": "/state/partition1/job-58968762",
    "topology_addr": "gr067",
    "topology_addr_pattern": "node",
    "tres_per_task": "cpu:8",
    "umask": "0022"
  },
  "cudaVersion": "12.2"
}