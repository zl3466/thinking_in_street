  0%|                                                                                                                                                                                      | 0/1191 [00:00<?, ?it/s]/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None
  warnings.warn(
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
path: ['/scratch/zl3466/dataset/NuScenes/train/sweeps/CAM_FRONT/n015-2018-07-24-11-13-19+0800__CAM_FRONT__1532402341912460.jpg', '/scratch/zl3466/dataset/NuScenes/train/samples/CAM_FRONT/n015-2018-07-24-11-13-19+0800__CAM_FRONT__1532402342362460.jpg', '/scratch/zl3466/dataset/NuScenes/train/sweeps/CAM_FRONT/n015-2018-07-24-11-13-19+0800__CAM_FRONT__1532402342762460.jpg']
problem_id: 24
prompt_length: 537
Error in reward_fn for question_type 'list': invalid syntax (<unknown>, line 0)
tensor([0.0000, 0.1000, 0.1000, 1.1000], device='cuda:0')
tensor([ 60, 479, 357, 136], device='cuda:0')
[2025-04-03 12:05:15,522] [WARNING] [stage3.py:2139:step] 1 pytorch allocator cache flushes since last step. this happens when there is high memory pressure and is detrimental to performance. if this is happening frequently consider adjusting settings to reduce memory consumption. If you are unable to make the cache flushes go away consider adding get_accelerator().empty_cache() calls in your training loop to ensure that all ranks flush their caches at the same time
  0%|‚ñè                                                                                                                                                                         | 1/1191 [02:49<56:08:06, 169.82s/it]Traceback (most recent call last):
{'loss': 0.0, 'grad_norm': 5.9054284989867325, 'learning_rate': 9.9999826053386e-07, 'completion_length': 285.375, 'rewards/accuracy_reward': 0.07500000298023224, 'rewards/format_reward': 0.25, 'all_wrong': 0.0, 'all_correct': 0.0, 'temporal_rewards': 1.0, 'reward': 0.32500001788139343, 'reward_std': 0.5188127756118774, 'kl': 0.0, 'epoch': 0.0}
path: ['/scratch/zl3466/dataset/NuScenes/train/sweeps/CAM_FRONT/n008-2018-08-01-15-52-19-0400__CAM_FRONT__1533153280362404.jpg', '/scratch/zl3466/dataset/NuScenes/train/samples/CAM_FRONT/n008-2018-08-01-15-52-19-0400__CAM_FRONT__1533153280762404.jpg', '/scratch/zl3466/dataset/NuScenes/train/sweeps/CAM_FRONT/n008-2018-08-01-15-52-19-0400__CAM_FRONT__1533153281162404.jpg']
problem_id: 12
prompt_length: 537
Error in reward_fn for question_type 'list': object of type 'NoneType' has no len()
tensor([1.1000, 0.1000, 0.1000, 1.0000], device='cuda:0')
tensor([249,  17,  19, 246], device='cuda:0')
  File "/scratch/zl3466/github/thinking_in_street/./train/localization/grpo.py", line 587, in <module>
    main(script_args, training_args, model_args)
  File "/scratch/zl3466/github/thinking_in_street/./train/localization/grpo.py", line 576, in main
    trainer.train()
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 3740, in training_step
    self.accelerator.backward(loss, **kwargs)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/accelerate/accelerator.py", line 2351, in backward
    self.deepspeed_engine_wrapped.backward(loss, **kwargs)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/accelerate/utils/deepspeed.py", line 266, in backward
    self.engine.backward(loss, **kwargs)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 2187, in backward
    self._do_optimizer_backward(loss, retain_graph)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 2133, in _do_optimizer_backward
    self.optimizer.backward(loss, retain_graph=retain_graph)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
    ret_val = func(*args, **kwargs)
              ^^^^^^^^^^^^^^^^^^^^^
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/zero/stage3.py", line 2284, in backward
    self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
    scaled_loss.backward(retain_graph=retain_graph)
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
[rank0]: Traceback (most recent call last):
[rank0]:   File "/scratch/zl3466/github/thinking_in_street/./train/localization/grpo.py", line 587, in <module>
[rank0]:     main(script_args, training_args, model_args)
[rank0]:   File "/scratch/zl3466/github/thinking_in_street/./train/localization/grpo.py", line 576, in main
[rank0]:     trainer.train()
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 2241, in train
[rank0]:     return inner_training_loop(
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 2548, in _inner_training_loop
[rank0]:     tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
[rank0]:                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/transformers/trainer.py", line 3740, in training_step
[rank0]:     self.accelerator.backward(loss, **kwargs)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/accelerate/accelerator.py", line 2351, in backward
[rank0]:     self.deepspeed_engine_wrapped.backward(loss, **kwargs)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/accelerate/utils/deepspeed.py", line 266, in backward
[rank0]:     self.engine.backward(loss, **kwargs)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 2187, in backward
[rank0]:     self._do_optimizer_backward(loss, retain_graph)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/engine.py", line 2133, in _do_optimizer_backward
[rank0]:     self.optimizer.backward(loss, retain_graph=retain_graph)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/utils/nvtx.py", line 20, in wrapped_fn
[rank0]:     ret_val = func(*args, **kwargs)
[rank0]:               ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/zero/stage3.py", line 2284, in backward
[rank0]:     self.loss_scaler.backward(loss.float(), retain_graph=retain_graph)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/deepspeed/runtime/fp16/loss_scaler.py", line 63, in backward
[rank0]:     scaled_loss.backward(retain_graph=retain_graph)
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/_tensor.py", line 626, in backward
[rank0]:     torch.autograd.backward(
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/autograd/__init__.py", line 347, in backward
[rank0]:     _engine_run_backward(
[rank0]:   File "/scratch/zl3466/env/thinking-in-street/lib/python3.11/site-packages/torch/autograd/graph.py", line 823, in _engine_run_backward
[rank0]:     return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]: KeyboardInterrupt
